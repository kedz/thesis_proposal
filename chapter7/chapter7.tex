\section{Conclusion}

In this thesis we have proposed to tackle two central problems for 
summarization: selecting salient information for summary inclusion and
generating text that is grounded in the underlying structured or text data. 
Our experiments on the salience problem spans many different summarization
scenarios, including the very challenging stream summarization task.
We also show how to incorporate salience estimation into two very different
paradigms, exemplar based clustering and learning-to-search.
We also contribute analysis as to the behavior of several deep learning models
of sentence salience, and,  based on these experiments, propose a novel
word importance estimation model, with applications to single and 
multi-document summarization. We hope that these sections of the thesis
form a flexible collection of strategies useful to a broad range of 
researchers in summarization. This work is diminished, however,
if we do not
have robust generation algorithms that do not hallucinate information.
We believe the final chapter on faithful generation will prove a useful 
paradigm for dealing with errorful generation outputs. We also believe
that faithful generation can be useful on a variety of text generation tasks
beyond just summarization, e.g. data-to-text generation.

