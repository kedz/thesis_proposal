\section{Faithful Text Generation}
\label{sec:chapter5}

Sections~\ref{sec:feature_salience}~and~\ref{sec:deep_learning_salience}
have focused on identifying the most important content for summary inclusion,
while punting somewhat on summary generation -- extractive summarization 
minimizes significantly the burden of creating fluent text. 
Abstractive text generation adds significant challenges to summary creation, 
but its benefits are many: the ability to achieve tighter compression ratios
for space constrained scenarios \citep{fan2017controllable}, the potential
to target different reading levels \citep{margarido2008automatic}
or style \citep{shen2017style}, and more pragmatically, in
an increasingly copy-protected web, may be the only legal option for content
aggregation services \citep{kassam2014google}.

With this expressive power comes the danger that the generated text may
misrepresent or misconstrue the source material. Trust in machine learning
models is increasingly being recognized as an important factor in user 
adoption \citep{ribeiro2016should}, and mistakes of this kind will be extremely
important for users relying summarization to make high stakes decisions.

\input{chapter5/figures/5_example1.tex}

We propose modeling text generation as a two player game between the generator
and recognizer, akin to an auto-encoder \citep{ae}. 
First, we provide as input to the 
generator some evidence (e.g., raw text or structured data like entries 
from a database). Conditioned on the evidence, the generator must produce 
a list of candidate utterances describing the evidence. The recognizer
reranks the candiates based on the likelihood of predicting the evidence
from the evidence. See \autoref{fig:fgen_example1} for an example 
where we have biographical data (structured data about name, nationality, 
occupation, etc.), and we generate several plausible and implausible 
candidates that are evaluated by the recognizer.

While we will experiment with a variety of loss functions to find something
that works empirically well, we expect in principal to train the generator
to maximize the expected likelihood of evidence under the recognizer.




We also think there are interesting applications where the evidence is
is not an entry in a database, but rather a distribution. For example,
if some information is not known, we would prefer outputs 
not a fact 



