Automatic text summarization is a long standing NLP problem that has recently 
seen an uptick in interest due to flexible, high capacity deep learning based 
sequence-to-sequence transduction models. 
While many researchers are turning to complex neural networks to perform
end-to-end summary generation, we argue that this unnecessarily obscures
the underlying sub-tasks for summarization. Instead, we propose an alternative
research agenda, focusing on two key summarization subtasks: 
\textit{i)} estimating the general importance of text content for summary 
inclusion, and \textit{ii)} generating text that is faithful, a notion we 
formally define, to said important content. With respect to problem \textit{i)}
we propose several novel methods for working in both low context, streaming
news scenarios, as well as, standard single document summarization settings,
including feature-based and deep learning models of content importance.
On the latter problem, we study the utility of using extractive 
summarization algorithms as a preprocessing stage for a sequence-to-sequence 
based abstractive summarizer, and finally introduce a novel algorithm for
generating text that is faithful, i.e. respects prior beliefs about structured 
knowledge in a database, in an effort to provide stronger guarantees 
about summary reliability.

